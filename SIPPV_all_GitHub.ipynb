{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pageheader_rose2_babies.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIPPV ventilation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Dr Gusztav Belteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook imports all files (slow_text, slow_settings, slow_measurements) of the first service evaluation (**DG001-DG060**) and stores them as dictionaries of DataFrames. It filters slow_measurements data to remove HFOV periods. It then limits recordings to continuous PC-AC (SIPPV) periods (1 per recoridng) using manual lookup of the recordings. After some preprocessing the data it exports the data to pickle archives: *slow_measurements_sippv_1, slow_measurements_sippv_2, slow_measurements_sippv_3*. Exporting it to three archives is necessary due to the size of data.\n",
    "\n",
    "*Preprocessing done on the data:*\n",
    "\n",
    "*  Resampling to 1 second to remove half empty rows (parameters were retrieved in two batches for each second, half a parameters were taken in each batch. Resampling combines them into one. \n",
    "*  Only SIPPV data are kept (this is done in part by manual lookup of ventilator settings).\n",
    "*  Normalizing the relevant parameters (VTs, MVs) to body weight. Original non-normalized data are also kept.\n",
    "*  Changing column names to more legible and intuitive ones.\n",
    "*  Adding the set backup respiratory rate (*RR*) to the data. \n",
    "*  Marking if leak compensation was on or not and adding this info to the DataFrames as a categorical variable\n",
    "*  Adding the recordings' names to the DataFrames\n",
    "*  Removing some unimportant (additional time stamps) columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries and setting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.style.use('classic')\n",
    "matplotlib.rcParams['figure.facecolor'] = 'w'\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom functions from own module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb_loader import *\n",
    "from gb_stats import *\n",
    "from gb_transform import *\n",
    "from gb_visualizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and set the working directory and the directory to write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic of the Notebook which will also be the name of the subfolder containing results\n",
    "TOPIC = 'SIPPV_all'\n",
    "\n",
    "# Name of the external hard drive\n",
    "DRIVE = 'GUSZTI'\n",
    "\n",
    "# Directory containing clinical and blood gas data\n",
    "CWD = '/Users/guszti/ventilation_draeger'\n",
    "\n",
    "# Directory on external drive to read the ventilation data from\n",
    "DIR_READ = '/Volumes/%s/Draeger/service_evaluation_old' % DRIVE\n",
    "\n",
    "# Directory to write results and selected images to \n",
    "if not os.path.isdir('%s/%s/%s' % (CWD, 'Analyses', TOPIC)):\n",
    "    os.makedirs('%s/%s/%s' % (CWD, 'Analyses', TOPIC))\n",
    "DIR_WRITE = '%s/%s/%s' % (CWD, 'Analyses', TOPIC)\n",
    "\n",
    "# Images and raw data will be written on an external hard drive\n",
    "if not os.path.isdir('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)):\n",
    "    os.makedirs('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC))\n",
    "DATA_DUMP = '/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CWD)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of the  recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of all recordings\n",
    "\n",
    "recordings = ['DG001', 'DG002_1', 'DG002_2', 'DG003', 'DG004', 'DG005_1', 'DG005_2', 'DG005_3', \n",
    "              'DG006_1', 'DG006_2', 'DG006_3', 'DG007', 'DG008', 'DG009', 'DG010', 'DG011', \n",
    "              'DG012', 'DG013', 'DG014', 'DG015', 'DG016', 'DG017', 'DG018_1', 'DG018_2', 'DG019',\n",
    "              'DG020', 'DG021', 'DG022', 'DG023', 'DG024',  'DG025', 'DG026', 'DG027', 'DG028', \n",
    "              'DG029', 'DG030', 'DG031', 'DG032_1', 'DG032_2', 'DG033', 'DG034', 'DG035', 'DG036', \n",
    "              'DG037', 'DG038_1', 'DG038_2', 'DG039', 'DG040_1', 'DG040_2', 'DG041', 'DG042', \n",
    "              'DG043', 'DG044', 'DG045', 'DG046_1', 'DG046_2', 'DG047', 'DG048', 'DG049', 'DG050',\n",
    "              'DG051_1', 'DG051_2', 'DG052', 'DG053', 'DG054', 'DG055', 'DG056', 'DG057', 'DG058',\n",
    "              'DG059', 'DG060']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clinical details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details = pd.read_excel('%s/data_grabber_patient_data_combined_old.xlsx' % CWD)\n",
    "clinical_details.index = clinical_details['Recording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clinical_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weights = {}\n",
    "for recording in recordings:\n",
    "    current_weights[recording] = clinical_details.loc[recording, 'Current weight' ] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator modes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes = {}\n",
    "\n",
    "for recording in recordings:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_text_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ, recording, filename) for filename in files]\n",
    "    vent_modes[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes_selected = {} # only important mode parameters are kept in this one\n",
    "\n",
    "for recording in recordings:\n",
    "    vent_modes_selected[recording] = vent_mode_cleaner(vent_modes[recording])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings = {}\n",
    "\n",
    "for recording in recordings:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_setting_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ, recording, filename) for filename in files]\n",
    "    vent_settings[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings_selected = {} # only important mode parameters are kept in this one\n",
    "\n",
    "for recording in recordings:\n",
    "    vent_settings_selected[recording] = vent_settings_cleaner(vent_settings[recording])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify recordings that have SIPPV periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify recordings which have PC-AC mode ( = SIPPV) and collect their name in a list\n",
    "# Print those ones which do not have PC_AC periods\n",
    "recordings_sippv = []\n",
    "\n",
    "for recording in recordings:\n",
    "    a = (vent_modes_selected[recording]['Text'])\n",
    "    if ' Mode PC-AC' in a.values:\n",
    "        recordings_sippv.append(recording)\n",
    "    else:\n",
    "        # print('%s does not contain SIPPV ventilation' % recording)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordings_sippv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings_sippv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator parameters obtained with 1Hz sampling rate (\"slow measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slow_measurements = {}\n",
    "\n",
    "for recording in recordings_sippv:\n",
    "    \n",
    "    flist = os.listdir('%s/%s' % (DIR_READ, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_measurement_finder(flist)\n",
    "    print('Loading recording %s' % recording)\n",
    "    print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ, recording, filename) for filename in files]\n",
    "    slow_measurements[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample to remove half-empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for recording in recordings_sippv:\n",
    "    slow_measurements[recording] = slow_measurements[recording].resample('1S').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit the intervals to SIPPV (PC-AC) periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the recordings in seconds BEFORE removing non-SIPPV periods: \\n')\n",
    "for recording in recordings_sippv:\n",
    "    print('%-10s %-10.d' % (recording, len(slow_measurements[recording])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit recordings to ** continuous PC-AC (SIPPV)** periods using **manual lookup** of the recordings (The other recordings in **\"recordings_sippv\"** are completely PC-AC (SIPPV) recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG001'] = slow_measurements['DG001']['2015-09-25 13:42:42':'2015-09-26 10:27:19']\n",
    "slow_measurements['DG005_1'] = slow_measurements['DG005_1']['2015-10-13 08:54:08':'2015-10-13 14:48:34']\n",
    "slow_measurements['DG005_2'] = slow_measurements['DG005_2']['2015-10-23 22:30:38':'2015-10-24 11:18:40']\n",
    "slow_measurements['DG015'] = slow_measurements['DG015']['2015-11-30 13:16:46':'2015-11-30 17:04:37']\n",
    "slow_measurements['DG016'] = slow_measurements['DG016']['2015-12-07 18:16:17':'2015-12-08 08:50:53']\n",
    "slow_measurements['DG017'] = slow_measurements['DG017']['2015-12-08 14:29:23':'2015-12-09 17:45:53']\n",
    "slow_measurements['DG018_1'] = slow_measurements['DG018_1']['2015-12-11 22:15:28':'2015-12-13 01:06:49']\n",
    "slow_measurements['DG018_2'] = slow_measurements['DG018_2']['2015-12-17 21:27:23':'2015-12-17 22:50:37']\n",
    "slow_measurements['DG022'] = slow_measurements['DG022']['2016-01-06 03:04:16':'2016-01-06 06:22:55']\n",
    "slow_measurements['DG027'] = slow_measurements['DG027']['2016-01-29 12:42:06':'2016-02-01 16:38:26']\n",
    "slow_measurements['DG032_1'] = slow_measurements['DG032_1']['2016-03-07 14:58:29':'2016-03-09 09:47:21']\n",
    "slow_measurements['DG032_2'] = slow_measurements['DG032_2']['2016-03-24 13:45:36':'2016-03-26 02:06:39']\n",
    "slow_measurements['DG034'] = slow_measurements['DG034']['2016-03-26 15:17:23':'2016-03-28 16:44:59']\n",
    "slow_measurements['DG036'] = slow_measurements['DG036']['2016-04-25 15:47:09':'2016-04-25 15:49:29']\n",
    "slow_measurements['DG038_1'] = slow_measurements['DG038_1']['2016-05-11 11:21:16':'2016-05-11 20:26:32']\n",
    "slow_measurements['DG040_1'] = slow_measurements['DG040_1']['2016-06-09 10:00:31':'2016-06-09 15:56:34']\n",
    "slow_measurements['DG040_2'] = slow_measurements['DG040_2']['2016-06-24 08:39:40':'2016-06-24 15:29:44']\n",
    "slow_measurements['DG046_1'] = slow_measurements['DG046_1']['2016-07-12 15:15:02':'2016-07-12 15:16:13']\n",
    "slow_measurements['DG049'] = slow_measurements['DG049']['2016-08-31 15:56:01':'2016-09-02 05:24:51']\n",
    "slow_measurements['DG050'] = slow_measurements['DG050']['2016-09-05 08:48:28':'2016-09-05 11:20:57']\n",
    "slow_measurements['DG053'] = slow_measurements['DG053']['2016-10-15 10:09:39':'2016-10-15 10:18:35']\n",
    "slow_measurements['DG056'] = slow_measurements['DG056']['2016-11-12 15:52:36':'2016-11-13 12:02:08']\n",
    "slow_measurements['DG060'] = slow_measurements['DG060']['2017-02-15 19:27:28':'2017-02-21 10:08:52']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the recordings in seconds AFTER removing non-SIPPV periods: \\n')\n",
    "for recording in recordings_sippv:\n",
    "    print('%-10s %-10.d' % (recording, len(slow_measurements[recording])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise parameters to the body weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the tidal volumes for body weight kilogram\n",
    "for recording in recordings_sippv:\n",
    "    try:\n",
    "        a = slow_measurements[recording]\n",
    "        a['VT_kg']       = a['5001|VT [mL]'] / current_weights[recording]\n",
    "        a['VTi_kg']      = a['5001|VTi [mL]'] / current_weights[recording]\n",
    "        a['VTe_kg']      = a['5001|VTe [mL]'] / current_weights[recording]\n",
    "        a['VTmand_kg']   = a['5001|VTmand [mL]'] / current_weights[recording]\n",
    "        a['VTspon_kg']   = a['5001|VTspon [mL]'] / current_weights[recording]\n",
    "        a['VTimand_kg']  = a['5001|VTimand [mL]'] / current_weights[recording]\n",
    "        a['VTemand_kg']  = a['5001|VTemand [mL]'] / current_weights[recording]\n",
    "        a['VTispon_kg']  = a['5001|VTispon [mL]'] / current_weights[recording]\n",
    "        a['VTespon_kg']  = a['5001|VTespon [mL]'] / current_weights[recording]\n",
    "    except KeyError:\n",
    "        print('%s does not have all of the parameters' % recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising minute volumes for body weight kilograms\n",
    "for recording in recordings_sippv:\n",
    "    try:\n",
    "        a = slow_measurements[recording]\n",
    "        a['MV_kg'] =      a['5001|MV [L/min]'] / current_weights[recording]\n",
    "        a['MVi_kg'] =     a['5001|MVi [L/min]'] / current_weights[recording]\n",
    "        a['MVe_kg'] =     a['5001|MVe [L/min]'] / current_weights[recording]\n",
    "        a['MVemand_kg'] = a['5001|MVemand [L/min]'] / current_weights[recording]\n",
    "        a['MVespon_kg'] = a['5001|MVespon [L/min]'] / current_weights[recording]\n",
    "        a['MVleak_kg'] =  a['5001|MVleak [L/min]'] / current_weights[recording]\n",
    "    except KeyError:\n",
    "        print('%s does not have all of the parameters' % recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to rename \"clumsy\" column names with simple ones\n",
    "\n",
    "old = ['5001|VT [mL]', '5001|VTi [mL]', '5001|VTe [mL]', \n",
    "       '5001|VTemand [mL]', '5001|VTespon [mL]',\n",
    "       '5001|VTimand [mL]', '5001|VTispon [mL]', \n",
    "       '5001|VTmand [mL]', '5001|VTspon [mL]',\n",
    "       '5001|MV [L/min]', '5001|MVe [L/min]', '5001|MVemand [L/min]', '5001|MVespon [L/min]',\n",
    "       '5001|MVi [L/min]', '5001|MVleak [L/min]', '5001|% MVspon [%]', '5001|% leak [%]', \n",
    "       '5001|C20/Cdyn [no unit]', '5001|Cdyn [L/bar]', '5001|E (I:E) [no unit]', '5001|E [mbar/L]', \n",
    "       '5001|EIP [mbar]', '5001|FiO2 [%]', '5001|FlowDev [L/min]', '5001|I (I:E) [no unit]', \n",
    "       '5001|I:Espon (E-Part) [no unit]', '5001|I:Espon (I-Part) [no unit]', '5001|PEEP [mbar]',\n",
    "       '5001|PIP [mbar]', '5001|Pmean [mbar]', '5001|Pmin [mbar]', '5001|R [mbar/L/s]', '5001|RR [1/min]',\n",
    "       '5001|RRmand [1/min]', '5001|RRspon [1/min]', '5001|Rpat [mbar/L/s]', '5001|TC [s]', '5001|TCe [s]',\n",
    "       '5001|Tispon [s]', '5001|r2 [no unit]']\n",
    "\n",
    "new = ['VT', 'VTi', 'VTe', \n",
    "       'VTemand', 'VTespon', \n",
    "       'VTimand', 'VTispon', \n",
    "       'VTmand', 'VTspon',\n",
    "       'MV', 'MVe', 'MVemand', 'MVespon', \n",
    "       'MVi', 'MVleak', 'MVspon%', 'leak%', \n",
    "       'C20_Cdyn', 'Cdyn', 'E_IE', 'E', \n",
    "       'EIP', 'FiO2', 'FlowDev', 'I_IE', \n",
    "       'I_Espon_E', 'I_Espon_I', 'PEEP',\n",
    "       'PIP', 'Pmean', 'Pmin', 'R', 'RR',\n",
    "       'RRmand', 'RRspon', 'Rpat', 'TC', 'TCe',\n",
    "       'Tispon', 'r2']\n",
    "\n",
    "rename_dict = dict(zip(old, new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column names and removing unimportant columns \n",
    "\n",
    "for recording in recordings_sippv:\n",
    "    try:\n",
    "        slow_measurements[recording].rename(columns=rename_dict, inplace=True)\n",
    "        to_delete = [par for par in list(slow_measurements[recording]) \n",
    "                     if par.startswith('5001') or par.startswith('8272')]\n",
    "        slow_measurements[recording] = slow_measurements[recording].drop(to_delete, axis = 1)\n",
    "    except KeyError:\n",
    "        print('%s does not have all of the parameters' % recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the set respiratory rate and adding it to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_set = {}\n",
    "for recording in recordings_sippv:\n",
    "    RR_set[recording] = vent_settings_selected[recording][vent_settings_selected[recording].Id == 'RR'].copy()\n",
    "    RR_set[recording]['RR_set'] = RR_set[recording]['Value New']\n",
    "    RR_set[recording] = RR_set[recording][['RR_set']]\n",
    "    RR_set[recording] = RR_set[recording].reindex(slow_measurements[recording].index, method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_sippv:\n",
    "    slow_measurements[recording] = pd.concat([slow_measurements[recording], RR_set[recording]],\n",
    "                                            join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark if leak compensation was on or not and add it to the DataFrames as a categorical variable:\n",
    "\n",
    "\n",
    "**'leak_comp'** = **VTmand_kg** - **VTemand_kg**\n",
    "\n",
    "*  If the leak-compensation if off VTmand = VTemand. The targeted parameter is VTemand.\n",
    "*  If leak-compesation is on, VTmand > VTemand. The targeted parameter is VTmand\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new columns in the dataframe with the amount of leak compensation\n",
    "# This value is close to 0 if leak compensation was off as the targeted VT is VTemand in that case\n",
    "# When leak compensation is on, 'VTmand' is the sum of 'VTemand' and the calculated expiratory leak\n",
    "for recording in recordings_sippv:\n",
    "    slow_measurements[recording]['leak_comp'] = slow_measurements[recording]['VTmand_kg'] - \\\n",
    "        slow_measurements[recording]['VTemand_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_sippv:\n",
    "    if slow_measurements[recording]['leak_comp'].mean() > 0.001:\n",
    "        slow_measurements[recording]['leak_comp_ON'] = 1 \n",
    "    else:\n",
    "        slow_measurements[recording]['leak_comp_ON'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the recording's name to the DataFrames as a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_sippv:\n",
    "    slow_measurements[recording]['recording'] = recording "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_sippv:\n",
    "    slow_measurements[recording].drop(['Time [ms]', 'Rel.Time [s]'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all processed DataFrames to pickle archives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slow measurements directory is too large to be written into pickle archive in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = recordings_sippv[:20]; rec2 = recordings_sippv[20:40]; \n",
    "rec3 = recordings_sippv[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_1 = { key: value for key, value in slow_measurements.items() if key in rec1}\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_sippv_1'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements_1, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_2 = { key: value for key, value in slow_measurements.items() if key in rec2}\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_sippv_2'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements_2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_3 = { key: value for key, value in slow_measurements.items() if key in rec3}\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_sippv_3'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements_3, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
